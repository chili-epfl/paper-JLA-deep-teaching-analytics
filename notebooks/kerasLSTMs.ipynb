{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": false,
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using Theano backend.\n"
     ]
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "import time\n",
    "import csv\n",
    "from keras.models import Sequential\n",
    "from keras.layers.core import Dense, Activation, Dropout\n",
    "from keras.layers.recurrent import LSTM\n",
    "\n",
    "import pandas as pd\n",
    "from random import random\n",
    "\n",
    "%matplotlib inline\n",
    "import matplotlib.pyplot as plt\n",
    "np.random.seed(1234)\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['V993',\n",
       " 'V994',\n",
       " 'V995',\n",
       " 'V996',\n",
       " 'V997',\n",
       " 'V998',\n",
       " 'V999',\n",
       " 'V1000',\n",
       " 'Activity',\n",
       " 'Social']"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data = pd.read_csv(\"../data/processed/train.csv\")\n",
    "#data.describe()\n",
    "list(data.columns.values[7550:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['Unnamed: 0',\n",
       " 'session',\n",
       " 'timestamp',\n",
       " 'value.Mean',\n",
       " 'value.SD',\n",
       " 'value.Fix',\n",
       " 'value.Sac',\n",
       " 'value.Fix.Dur',\n",
       " 'value.Fix.Disp',\n",
       " 'value.Sac.Dur']"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "list(data.columns.values[0:10])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "# Add dummy variables for the target variables\n",
    "#dumAct = pd.get_dummies(data.Activity)\n",
    "#dumSoc = pd.get_dummies(data.Social)\n",
    "#datadum = pd.concat([data, dumAct, dumSoc], axis=1)\n",
    "#plt.figure()\n",
    "#datadum['value.Mean'][1:100].plot()\n",
    "#datadum['EXP'][1:100].plot()\n",
    "#datadum['MON'][1:100].plot()\n",
    "testing = pd.read_csv(\"../data/processed/test.csv\")\n",
    "#testing.describe()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    Unnamed: 0                       session  timestamp  value.Mean  value.SD  \\\n",
      "0          462  case1-day1-session2-teacher1       5000    4.314267  0.306538   \n",
      "1          463  case1-day1-session2-teacher1      10000    4.345133  0.287732   \n",
      "2          464  case1-day1-session2-teacher1      15000    4.443455  0.452320   \n",
      "3          465  case1-day1-session2-teacher1      20000    4.220532  0.548338   \n",
      "4          466  case1-day1-session2-teacher1      25000    3.732533  0.318437   \n",
      "5          467  case1-day1-session2-teacher1      30000    3.518267  0.292483   \n",
      "6          468  case1-day1-session2-teacher1      35000    3.387708  0.313086   \n",
      "7          469  case1-day1-session2-teacher1      40000    3.529435  0.568454   \n",
      "8          470  case1-day1-session2-teacher1      45000    3.851000  0.527294   \n",
      "9          471  case1-day1-session2-teacher1      50000    3.763123  0.483854   \n",
      "10         472  case1-day1-session2-teacher1      55000    3.398472  0.505439   \n",
      "11         473  case1-day1-session2-teacher1      60000    3.153400  0.354198   \n",
      "12         474  case1-day1-session2-teacher1      65000    2.928467  0.320429   \n",
      "13         475  case1-day1-session2-teacher1      70000    3.188771  0.459525   \n",
      "14         476  case1-day1-session2-teacher1      75000    3.443787  0.298150   \n",
      "15         477  case1-day1-session2-teacher1      80000    3.288200  0.465429   \n",
      "16         478  case1-day1-session2-teacher1      85000    3.451467  0.535570   \n",
      "17         479  case1-day1-session2-teacher1      90000    3.597940  0.709510   \n",
      "18         480  case1-day1-session2-teacher1      95000    3.739934  0.685870   \n",
      "19         481  case1-day1-session2-teacher1     100000    3.738333  0.579035   \n",
      "20         482  case1-day1-session2-teacher1     105000    3.531933  0.604536   \n",
      "21         483  case1-day1-session2-teacher1     110000    3.500000  0.585400   \n",
      "22         484  case1-day1-session2-teacher1     115000    3.288239  0.555130   \n",
      "23         485  case1-day1-session2-teacher1     120000    3.114000  0.320290   \n",
      "24         486  case1-day1-session2-teacher1     125000    3.174533  0.297426   \n",
      "25         487  case1-day1-session2-teacher1     130000    3.295017  0.332787   \n",
      "26         488  case1-day1-session2-teacher1     135000    3.297674  0.436961   \n",
      "27         489  case1-day1-session2-teacher1     140000    3.254467  0.419339   \n",
      "28         490  case1-day1-session2-teacher1     145000    3.205200  0.572911   \n",
      "29         491  case1-day1-session2-teacher1     150000    3.239668  0.540033   \n",
      "30         492  case1-day1-session2-teacher1     155000    3.501130  0.289708   \n",
      "31         493  case1-day1-session2-teacher1     160000    3.753667  0.224853   \n",
      "32         494  case1-day1-session2-teacher1     165000    3.686867  0.400170   \n",
      "33         495  case1-day1-session2-teacher1     170000    3.436877  0.405485   \n",
      "34         496  case1-day1-session2-teacher1     175000    3.234352  0.651778   \n",
      "35         497  case1-day1-session2-teacher1     180000    3.065133  0.878588   \n",
      "36         498  case1-day1-session2-teacher1     185000    2.973223  0.673421   \n",
      "37         499  case1-day1-session2-teacher1     190000    2.819269  0.682291   \n",
      "38         500  case1-day1-session2-teacher1     195000    2.858333  0.718448   \n",
      "39         501  case1-day1-session2-teacher1     200000    3.095133  0.340201   \n",
      "40         502  case1-day1-session2-teacher1     205000    3.322392  0.478862   \n",
      "41         503  case1-day1-session2-teacher1     210000    3.534950  0.583060   \n",
      "42         504  case1-day1-session2-teacher1     215000    3.306933  0.965893   \n",
      "43         505  case1-day1-session2-teacher1     220000    3.151933  0.890162   \n",
      "44         506  case1-day1-session2-teacher1     225000    3.358405  0.742182   \n",
      "45         507  case1-day1-session2-teacher1     230000    3.385714  0.901443   \n",
      "46         508  case1-day1-session2-teacher1     235000    3.481533  0.682852   \n",
      "47         509  case1-day1-session2-teacher1     240000    3.692200  0.470334   \n",
      "48         510  case1-day1-session2-teacher1     245000    3.885249  0.440088   \n",
      "49         511  case1-day1-session2-teacher1     250000    3.892226  0.313402   \n",
      "50         512  case1-day1-session2-teacher1     255000    3.760800  0.295359   \n",
      "51         513  case1-day1-session2-teacher1     260000    3.783267  0.365716   \n",
      "52         514  case1-day1-session2-teacher1     265000    3.768638  0.326774   \n",
      "53         515  case1-day1-session2-teacher1     270000    3.562591  0.678732   \n",
      "54         516  case1-day1-session2-teacher1     275000    3.630400  0.715275   \n",
      "55         517  case1-day1-session2-teacher1     280000    3.859600  0.488048   \n",
      "56         518  case1-day1-session2-teacher1     285000    3.660532  0.617625   \n",
      "57         519  case1-day1-session2-teacher1     290000    3.212159  0.622963   \n",
      "58         520  case1-day1-session2-teacher1     295000    3.268067  0.559620   \n",
      "59         521  case1-day1-session2-teacher1     300000    3.588173  0.498963   \n",
      "           ...                           ...        ...         ...       ...   \n",
      "\n",
      "    value.Fix  value.Sac  value.Fix.Dur  value.Fix.Disp  value.Sac.Dur  \n",
      "0           1   0.099028     181.470588       67.880293      76.447368  \n",
      "1           1   0.268900     185.310345       75.417626      79.468750  \n",
      "2           0   0.345642     162.344828       81.276038      77.972222  \n",
      "3           0   0.225218     177.310345       77.998963      74.844444  \n",
      "4           1   0.297788     196.827586      114.818874      77.581395  \n",
      "5           1   0.262253     180.200000      105.913474      75.795455  \n",
      "6           0   0.211084     142.896552       97.254114      72.319149  \n",
      "7           0   0.263253     145.275862       93.224965      77.027778  \n",
      "8           1   0.139931     175.833333       61.870379      77.774194  \n",
      "9           3   0.071331     209.033333       65.464054      78.551724  \n",
      "10          2   0.277048     215.000000      113.210418      81.888889  \n",
      "11          0   0.388531     167.208333      117.700615      83.500000  \n",
      "12          0   0.318440     157.800000      101.338197      79.228571  \n",
      "13          0   0.267068     147.551724       85.640286      73.615385  \n",
      "14          0   0.261111     152.787879       92.297871      76.500000  \n",
      "15          1   0.333032     184.407407      116.126571      79.921053  \n",
      "16          1   0.412892     159.928571      106.726074      82.529412  \n",
      "17          0   0.303803     140.366667       91.748954      82.000000  \n",
      "18          1   0.273499     172.600000       82.697292      78.833333  \n",
      "19          1   0.260074     189.516129       70.141857      76.702703  \n",
      "20          0   0.244845     160.687500       54.956157      80.324324  \n",
      "21          0   0.298906     126.827586       78.969382      80.228571  \n",
      "22          0   0.361689     144.500000      135.845689      79.833333  \n",
      "23          0   0.356317     160.656250      153.676605      79.404762  \n",
      "24          0   0.281227     149.657143      113.699300      76.531915  \n",
      "25          0   0.301869     153.117647      114.571257      78.313725  \n",
      "26          0   0.301992     167.038462      147.983048      75.100000  \n",
      "27          0   0.298836     177.863636      121.759801      75.166667  \n",
      "28          0   0.286390     158.833333       95.874444      76.153846  \n",
      "29          0   0.253139     142.862069       68.678889      73.071429  \n",
      "30          0   0.253906     152.818182       67.124668      74.066667  \n",
      "31          0   0.229894     147.323529       78.997974      73.450000  \n",
      "32          0   0.251244     139.228571       88.289623      71.236842  \n",
      "33          0   0.265645     138.411765       97.976443      73.857143  \n",
      "34          0   0.236190     129.961538       85.976067      75.281250  \n",
      "35          0   0.219321     150.000000       78.962153      74.291667  \n",
      "36          0   0.186833     199.083333       92.061764      75.343750  \n",
      "37          0   0.149793     161.516129       68.442666      73.571429  \n",
      "38          0   0.172748     139.843750       54.758894      76.729730  \n",
      "39          0   0.230186     160.266667       77.419900      79.250000  \n",
      "40          0   0.243033     165.785714       92.157017      75.925000  \n",
      "41          0   0.259841     172.192308       74.731349      75.428571  \n",
      "42          0   0.244388     156.727273       60.047144      73.333333  \n",
      "43          0   0.206933     145.642857       64.451686      71.000000  \n",
      "44          0   1.378227     145.451613      103.867721      73.333333  \n",
      "45          0   1.608574     139.000000      126.783700      74.853659  \n",
      "46          0   0.416986     152.560000      112.522559      76.421053  \n",
      "47          0   0.280524     163.230769      130.695825      75.022727  \n",
      "48          0   0.225137     139.545455       80.297164      73.042553  \n",
      "49          0   0.219224     150.111111       62.198936      74.425532  \n",
      "50          1   0.305448     183.032258      100.755998      76.394737  \n",
      "51          2   0.353726     207.703704       93.907384      79.060606  \n",
      "52          2   0.302080     219.000000       87.329882      79.861111  \n",
      "53          1   0.328049     221.291667      119.246887      79.090909  \n",
      "54          0   0.240838     192.480000      107.549229      73.600000  \n",
      "55          0   0.217858     179.884615      111.829702      70.230769  \n",
      "56          0   0.295164     155.448276       92.642187      73.021277  \n",
      "57          0   0.241150     130.484848       59.173932      73.500000  \n",
      "58          0   0.211603     141.382353       84.194127      72.243243  \n",
      "59          0   0.240067     146.612903       96.994778      72.875000  \n",
      "          ...        ...            ...             ...            ...  \n",
      "\n",
      "[4507 rows x 10 columns]\n"
     ]
    }
   ],
   "source": [
    "#print data['Activity']\n",
    "print data.ix[:,0:10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": [
    "#TODO: split into train and test sets\n",
    "#Follow/mix:\n",
    "#https://github.com/Vict0rSch/deep_learning/tree/master/keras/recurrent\n",
    "#https://gist.github.com/hnykda/c362f0ad488e3b289394\n",
    "#https://github.com/fchollet/keras/blob/master/examples/imdb_lstm.py\n",
    "\n",
    "# Prepare the data\n",
    "# We cut out the last samples to match a multiple of our batch size (20)\n",
    "x_train = data.ix[0:4499,3:(data.shape[1]-2)]\n",
    "y_train = pd.get_dummies(data.Activity[0:4500]) \n",
    "print x_train.shape\n",
    "print y_train.shape\n",
    "x_val = testing.ix[0:1039,3:(testing.shape[1]-2)]\n",
    "y_val = pd.get_dummies(testing.Activity[0:1040])\n",
    "print x_val.shape\n",
    "print y_val.shape\n",
    "# From https://keras.io/getting-started/sequential-model-guide/\\\n",
    "data_dim = 7555\n",
    "timesteps = 10\n",
    "nb_classes = y_train.shape[1]\n",
    "batch_size = 20\n",
    "\n",
    "# expected input batch shape: (batch_size, timesteps, data_dim)\n",
    "# note that we have to provide the full batch_input_shape since the network is stateful.\n",
    "# the sample of index i in batch k is the follow-up for the sample i in batch k-1.\n",
    "\n",
    "model = Sequential()\n",
    "model.add(LSTM(200, return_sequences=True, stateful=True,\n",
    "               batch_input_shape=(batch_size, timesteps, data_dim)))\n",
    "model.add(LSTM(100, return_sequences=True, stateful=True))\n",
    "model.add(LSTM(50, stateful=True))\n",
    "model.add(Dense(nb_classes, activation='softmax'))\n",
    "\n",
    "model.compile(loss='categorical_crossentropy',\n",
    "              optimizer='rmsprop',\n",
    "              metrics=['accuracy'])\n",
    "model.fit(x_train, y_train,\n",
    "          batch_size=batch_size, nb_epoch=1,\n",
    "          validation_data=(x_val, y_val))\n",
    "score = model.evaluate(x_val, y_val, batch_size=batch_size)\n",
    "print scor"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 2",
   "language": "python",
   "name": "python2"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 2
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython2",
   "version": "2.7.6"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 0
}
